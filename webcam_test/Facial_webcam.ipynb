{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (7178, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, ToPILImage\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = 'C:/Users/PC/Desktop/CCN_MODEL_training/Fer2013_dataset/test'\n",
    "\n",
    "# Load the dataset\n",
    "data = []\n",
    "labels = []\n",
    "paths = []\n",
    "\n",
    "# Iterate through the dataset directory\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_dir = os.path.join(dataset_path, class_name)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        paths.append(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        data.append(img)\n",
    "        labels.append(class_name)\n",
    "\n",
    "# Convert to DataFrame and numpy arrays\n",
    "df = pd.DataFrame({'data': paths, 'label': labels})\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "\n",
    "# Take a small subset\n",
    "small_data = data[:500]\n",
    "small_labels = labels[:500]\n",
    "\n",
    "# Load the pre-trained model and processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"motheecreator/vit-Facial-Expression-Recognition\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"motheecreator/vit-Facial-Expression-Recognition\")\n",
    "\n",
    "# Get class names in the order of appearance\n",
    "class_names = list(dict.fromkeys(labels))  # Preserve original order without sorting\n",
    "label_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
    "numerical_labels = [label_to_index[label] for label in small_labels]\n",
    "\n",
    "# Preprocessing images\n",
    "transform = Compose([\n",
    "    ToPILImage(),                           # Convert NumPy array to PIL Image\n",
    "    Resize((224, 224)),                     # Resize to match model input\n",
    "    ToTensor(),                             # Convert to PyTorch Tensor\n",
    "    Normalize(mean=processor.image_mean,    # Normalize using processor values\n",
    "              std=processor.image_std)\n",
    "])\n",
    "\n",
    "processed_data = torch.stack([transform(image) for image in small_data])\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(processed_data).logits\n",
    "    predicted_labels = torch.argmax(predictions, dim=1).numpy()\n",
    "\n",
    "# Plotting function\n",
    "def plot_image(i, predictions, true_labels, images, class_names):\n",
    "    pred_label = predictions[i]\n",
    "    true_label = true_labels[i]\n",
    "    image = images[i]\n",
    "\n",
    "    # Determine color based on correctness\n",
    "    color = 'blue' if pred_label == true_label else 'red'\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Pred: {class_names[pred_label]}, True: {class_names[true_label]}\", color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Plot example\n",
    "i = 0  # Index of the image to visualize\n",
    "plot_image(i, predicted_labels, numerical_labels, small_data, class_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip show tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import Sequential  # Ensure Sequential is accessible\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"C:/Users/PC/Desktop/CCN_MODEL_training/webcam_test/Facial Expression Recognition.json\", \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "\n",
    "# Use a custom_objects dictionary to register Sequential\n",
    "model = model_from_json(model_json, custom_objects={\"Sequential\": Sequential})\n",
    "\n",
    "model.load_weights('C:/Users/PC/Desktop/CCN_MODEL_training/webcam_test/fer.h5')\n",
    "\n",
    "\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 46\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     47\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "face_haar_cascade = cv2.CascadeClassifier('C:/Users/PC/Desktop/CCN_MODEL_training/webcam_test/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:/Users/PC/Desktop/CCN_MODEL_training/webcam_test/Emotions.mp4\")\n",
    "\n",
    "emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, test_img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error capturing frame\")\n",
    "            continue\n",
    "        \n",
    "        gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "        faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces_detected:\n",
    "            cv2.rectangle(test_img, (x, y), (x + w, y + h), (255, 0, 0), thickness=7)\n",
    "            roi_gray = gray_img[y:y + w, x:x + h]\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "            \n",
    "            img_pixels = image.img_to_array(roi_gray)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "            img_pixels /= 255\n",
    "            \n",
    "            try:\n",
    "                predictions = model.predict(img_pixels)\n",
    "                max_index = np.argmax(predictions[0])\n",
    "                predicted_emotion = emotions[max_index]\n",
    "            except Exception as e:\n",
    "                print(f\"Error during prediction: {e}\")\n",
    "                predicted_emotion = \"Unknown\"\n",
    "\n",
    "            cv2.putText(test_img, predicted_emotion, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        resized_img = cv2.resize(test_img, (1300, 800))\n",
    "        cv2.imshow('Facial Emotion Analysis', resized_img)\n",
    "\n",
    "        key = cv2.waitKey(10)\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 67\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     68\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the face detection model\n",
    "face_haar_cascade = cv2.CascadeClassifier('C:/Users/PC/Desktop/CCN_MODEL_training/webcam_test/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the video file\n",
    "cap = cv2.VideoCapture(\"C:/Users/PC/Desktop/CCN_MODEL_training/webcam_test/Emotions.mp4\")\n",
    "\n",
    "# Define the emotions\n",
    "emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "speed_factor = 3\n",
    "frame_interval = int(fps / speed_factor)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, test_img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error capturing frame\")\n",
    "            break\n",
    "\n",
    "    \n",
    "        current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        if current_frame % frame_interval != 0:\n",
    "            continue\n",
    "\n",
    "        gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "        faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces_detected:\n",
    "            cv2.rectangle(test_img, (x, y), (x + w, y + h), (255, 0, 0), thickness=7)\n",
    "            roi_gray = gray_img[y:y + w, x:x + h]\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "            \n",
    "            img_pixels = image.img_to_array(roi_gray)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "            img_pixels /= 255\n",
    "            \n",
    "            try:\n",
    "                predictions = model.predict(img_pixels)\n",
    "                max_index = np.argmax(predictions[0])\n",
    "                predicted_emotion = emotions[max_index]\n",
    "            except Exception as e:\n",
    "                print(f\"Error during prediction: {e}\")\n",
    "                predicted_emotion = \"Unknown\"\n",
    "\n",
    "            cv2.putText(test_img, predicted_emotion, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        resized_img = cv2.resize(test_img, (1600, 750))\n",
    "        cv2.imshow('Facial Emotion Analysis', resized_img)\n",
    "\n",
    "\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        key = cv2.waitKey(10)\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP_HMK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
